{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Position  Driver Standings\n",
      "0  13.119203            329756\n",
      "1  13.119203            329861\n",
      "2  13.119203            329963\n",
      "3  13.119203            330066\n",
      "4  13.119203            330166\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('test.csv', parse_dates=['dob', 'date'])\n",
    "\n",
    "# Replace '\\\\N' with NaN\n",
    "test_df = test_df.replace('\\\\N', np.nan)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['fastestLap', 'rank', 'fastestLapTime', 'time_y', 'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time', 'driver_num', 'driver_code', 'resultId', 'driverId', 'constructorId', 'number', 'grand_prix', 'date']\n",
    "test_df = test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Create derived features\n",
    "test_df['experience'] = test_df.groupby('driverRef')['round'].transform('count')\n",
    "test_df['win_ratio'] = test_df['wins'] / test_df['experience']\n",
    "test_df['laps_completed_ratio'] = test_df['laps'] / test_df.groupby('racerId')['laps'].transform('max')\n",
    "test_df['points_per_race'] = test_df['points'] / test_df['experience']\n",
    "test_df['qualification_performance'] = test_df['grid'] / test_df.groupby('racerId')['grid'].transform('max')\n",
    "test_df['constructor_performance'] = test_df.groupby('constructorRef')['points'].transform('mean')\n",
    "test_df['track_familiarity'] = test_df.groupby(['driverRef', 'circuitId'])['round'].transform('count')\n",
    "test_df['season_performance'] = test_df.groupby(['driverRef', 'year'])['points'].transform('cumsum')\n",
    "test_df['recent_form'] = test_df.groupby('driverRef')['points'].transform(lambda x: x.rolling(window=5, min_periods=1).mean())\n",
    "\n",
    "test_df['timetaken_in_millisec'] = pd.to_numeric(test_df['timetaken_in_millisec'], errors='coerce')\n",
    "test_df['timetaken_in_seconds'] = test_df['timetaken_in_millisec'] / 1000\n",
    "test_df['avg_laptime'] = test_df['timetaken_in_seconds'] / test_df['laps']\n",
    "\n",
    "# Handle missing values using IterativeImputer for numeric and SimpleImputer for categorical\n",
    "numeric_features = test_df.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = test_df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "numeric_imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "test_df[numeric_features] = numeric_imputer.fit_transform(test_df[numeric_features])\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "test_df[categorical_features] = categorical_imputer.fit_transform(test_df[categorical_features])\n",
    "\n",
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "for col in categorical_features:\n",
    "    test_df[col] = le.fit_transform(test_df[col].astype(str))\n",
    "\n",
    "# Select features for the model\n",
    "features = ['grid', 'points', 'laps', 'timetaken_in_seconds', 'max_speed', \n",
    "            'experience', 'win_ratio', 'laps_completed_ratio',\n",
    "            'points_per_race', 'qualification_performance', 'constructor_performance',\n",
    "            'track_familiarity', 'season_performance', 'recent_form',\n",
    "            'avg_laptime', 'driverRef', 'nationality', 'constructorRef', \n",
    "            'status', 'round', 'year']\n",
    "\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Load the scaler and model\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Scale the test features\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict positions\n",
    "test_df['position'] = model.predict(X_test_scaled)\n",
    "\n",
    "# Ensure result_driver_standing column exists\n",
    "test_df['result_driver_standing'] = le.fit_transform(test_df['result_driver_standing'].astype(str))\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_df = test_df[['position', 'result_driver_standing']].rename(columns={\n",
    "    'position': 'Position',\n",
    "    'result_driver_standing': 'Driver Standings'\n",
    "})\n",
    "submission_df.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "# Print first few rows of the prediction DataFrame\n",
    "print(submission_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
